{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sacred python package\n",
    "\n",
    "Sacred is a tool to help you configure, organize, log and reproduce experiments. It is designed to do all the tedious overhead work that you need to do around your actual experiment in order to:\n",
    "\n",
    "* keep track of all the parameters of your experiment\n",
    "* easily run your experiment for different settings\n",
    "* save configurations for individual runs in a database\n",
    "* reproduce your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Installation\n",
    "`python -m pip install sacred`\n",
    "\n",
    "NOTE: not availeble in conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.27137e-14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = np.load('data/example_data.npy')\n",
    "    \n",
    "pca = PCA()\n",
    "    \n",
    "fit_pca = pca.fit(X)\n",
    "    \n",
    "enc = fit_pca.transform(X)\n",
    "    \n",
    "dec = fit_pca.inverse_transform(enc)\n",
    "        \n",
    "print(mean_squared_error(X, dec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Simplest sacred experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Presentation ex 1 - No observers have been added to this run\n",
      "INFO - Presentation ex 1 - Running command 'train'\n",
      "INFO - Presentation ex 1 - Started\n",
      "INFO - Presentation ex 1 - Result: 3.2713703301172695e-14\n",
      "INFO - Presentation ex 1 - Completed after 0:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7f978d098dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sacred import Experiment\n",
    "ex = Experiment('Presentation ex 1', interactive=True)\n",
    "\n",
    "@ex.main\n",
    "def train():\n",
    "    X = np.load('data/example_data.npy')\n",
    "    \n",
    "    pca = PCA()\n",
    "    \n",
    "    fit_pca = pca.fit(X)\n",
    "    \n",
    "    enc = fit_pca.transform(X)\n",
    "    \n",
    "    dec = fit_pca.inverse_transform(enc)\n",
    "        \n",
    "    return mean_squared_error(X, dec)\n",
    "\n",
    "ex.run()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "NOTE: since this presentation is a notebook, the interpeter is in interative mode, the extra parameter in the experiment definition is not advised in a normal experiment.\n",
    "Furthermore, instead of running the experiment in te last line, one can also change @ex.main to @ex.automain, making that last function unnecessary, however this is not possible in interactive mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Adding file observer\n",
    "While the example above seems to add code and just generating some extra stats about the experiment, sacred becomes very useful when we add an observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Presentation ex 1 - Running command 'train'\n",
      "INFO - Presentation ex 1 - Started run with ID \"1\"\n",
      "INFO - Presentation ex 1 - Result: 3.2713703301172695e-14\n",
      "INFO - Presentation ex 1 - Completed after 0:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7f978c650dd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sacred import Experiment\n",
    "ex = Experiment('Presentation ex 1', interactive=True)\n",
    "\n",
    "from sacred.observers import FileStorageObserver\n",
    "ex.observers.append(FileStorageObserver.create(basedir=os.path.join('runs', ex.path)))\n",
    "\n",
    "@ex.main\n",
    "def train():\n",
    "    X = np.load('data/example_data.npy')\n",
    "    \n",
    "    pca = PCA()\n",
    "    \n",
    "    fit_pca = pca.fit(X)\n",
    "    \n",
    "    enc = fit_pca.transform(X)\n",
    "    \n",
    "    dec = fit_pca.inverse_transform(enc)\n",
    "        \n",
    "    return mean_squared_error(X, dec)\n",
    "\n",
    "ex.run()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run.json', 'config.json', 'cout.txt']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"runs/Presentation ex 1/{}\".format(1)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"artifacts\": [],\n",
      "  \"command\": \"train\",\n",
      "  \"experiment\": {\n",
      "    \"base_dir\": \"/home/sako\",\n",
      "    \"dependencies\": [\n",
      "      \"IPython==5.3.0\",\n",
      "      \"numpy==1.13.1\",\n",
      "      \"platform==1.0.8\",\n",
      "      \"sacred==0.7.0\",\n",
      "      \"sklearn==0.19.0\"\n",
      "    ],\n",
      "    \"mainfile\": null,\n",
      "    \"name\": \"Presentation ex 1\",\n",
      "    \"repositories\": [],\n",
      "    \"sources\": []\n",
      "  },\n",
      "  \"heartbeat\": \"2017-09-10T13:01:06.246606\",\n",
      "  \"host\": {\n",
      "    \"ENV\": {},\n",
      "    \"cpu\": \"Intel(R) Xeon(R) CPU E5-2630L v4 @ 1.80GHz\",\n",
      "    \"hostname\": \"hostname\",\n",
      "    \"os\": [\n",
      "      \"Linux\",\n",
      "      \"Linux-version\"\n",
      "    ],\n",
      "    \"python_version\": \"3.6.1\"\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"command\": \"train\",\n",
      "    \"options\": {\n",
      "      \"--beat_interval\": null,\n",
      "      \"--capture\": null,\n",
      "      \"--comment\": null,\n",
      "      \"--debug\": false,\n",
      "      \"--enforce_clean\": false,\n",
      "      \"--file_storage\": null,\n",
      "      \"--force\": false,\n",
      "      \"--help\": false,\n",
      "      \"--loglevel\": null,\n",
      "      \"--mongo_db\": null,\n",
      "      \"--name\": null,\n",
      "      \"--pdb\": false,\n",
      "      \"--print_config\": false,\n",
      "      \"--priority\": null,\n",
      "      \"--queue\": false,\n",
      "      \"--sql\": null,\n",
      "      \"--tiny_db\": null,\n",
      "      \"--unobserved\": false\n",
      "    }\n",
      "  },\n",
      "  \"resources\": [],\n",
      "  \"result\": 3.2713703301172695e-14,\n",
      "  \"start_time\": \"2017-09-10T13:01:05.705190\",\n",
      "  \"status\": \"COMPLETED\",\n",
      "  \"stop_time\": \"2017-09-10T13:01:06.242840\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open (path + '/run.json', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"seed\": 193138917\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open (path + '/config.json', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open (path + '/cout.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "NOTE: Source is normally also saved in a separate folder, however this is not possible in interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining more sacred functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Presentation ex 2 - Running command 'train'\n",
      "INFO - Presentation ex 2 - Started run with ID \"1\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Fitting PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Presentation ex 2 - Result: 0.08322899043560028\n",
      "INFO - Presentation ex 2 - Completed after 0:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7f978c331f98>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sacred import Experiment\n",
    "ex = Experiment('Presentation ex 2', interactive=True)\n",
    "\n",
    "from sacred.observers import FileStorageObserver\n",
    "ex.observers.append(FileStorageObserver.create(basedir=os.path.join('runs', ex.path)))\n",
    "\n",
    "@ex.config\n",
    "def config():\n",
    "    data_path = 'data/example_data.npy'\n",
    "    \n",
    "    pca = KernelPCA(fit_inverse_transform=True)\n",
    "\n",
    "@ex.capture\n",
    "def data(data_path):\n",
    "    print('Reading data')\n",
    "    X = np.load(data_path)\n",
    "    \n",
    "    return X\n",
    "\n",
    "@ex.main\n",
    "def train(pca):\n",
    "    X = data()\n",
    "    \n",
    "    print('Fitting PCA')\n",
    "    fit_pca = pca.fit(X)\n",
    "    \n",
    "    enc = fit_pca.transform(X)\n",
    "    \n",
    "    dec = fit_pca.inverse_transform(enc)\n",
    "        \n",
    "    return mean_squared_error(X, dec)\n",
    "\n",
    "ex.run()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run.json', 'config.json', 'cout.txt']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"runs/Presentation ex 2/{}\".format(1)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data_path\": \"data/example_data.npy\",\n",
      "  \"pca\": {\n",
      "    \"py/object\": \"sklearn.decomposition.kernel_pca.KernelPCA\",\n",
      "    \"py/state\": {\n",
      "      \"_centerer\": {\n",
      "        \"py/object\": \"sklearn.preprocessing.data.KernelCenterer\",\n",
      "        \"py/state\": {\n",
      "          \"_sklearn_version\": \"0.19.0\"\n",
      "        }\n",
      "      },\n",
      "      \"_sklearn_version\": \"0.19.0\",\n",
      "      \"alpha\": 1.0,\n",
      "      \"coef0\": 1,\n",
      "      \"copy_X\": true,\n",
      "      \"degree\": 3,\n",
      "      \"eigen_solver\": \"auto\",\n",
      "      \"fit_inverse_transform\": true,\n",
      "      \"gamma\": null,\n",
      "      \"kernel\": \"linear\",\n",
      "      \"kernel_params\": null,\n",
      "      \"max_iter\": null,\n",
      "      \"n_components\": null,\n",
      "      \"n_jobs\": 1,\n",
      "      \"random_state\": null,\n",
      "      \"remove_zero_eig\": false,\n",
      "      \"tol\": 0\n",
      "    }\n",
      "  },\n",
      "  \"seed\": 925025430\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open (path + '/config.json', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# due to the interative mode, the capturing of the output does not work\n",
    "# however this file would contain everythin printed to the console, like the print statements in the code above\n",
    "with open (path + '/cout.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Adding more output files\n",
    "You would probably want to save some more files with statistics and outputs, there are two good ways of doing this, both having dat (dis-)advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Presentation ex 3 - Running command 'train'\n",
      "INFO - Presentation ex 3 - Started run with ID \"1\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Fitting PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Presentation ex 3 - Result: 0.08322899043560028\n",
      "INFO - Presentation ex 3 - Completed after 0:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7f978c3312e8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# parameters\n",
    "save_model = True\n",
    "\n",
    "from sacred import Experiment\n",
    "ex = Experiment('Presentation ex 3', interactive=True)\n",
    "\n",
    "from sacred.observers import FileStorageObserver\n",
    "ex.observers.append(FileStorageObserver.create(basedir=os.path.join('runs', ex.path)))\n",
    "\n",
    "@ex.config\n",
    "def config():\n",
    "    data_path = 'data/example_data.npy'\n",
    "    \n",
    "    pca = KernelPCA(fit_inverse_transform=True)\n",
    "\n",
    "@ex.capture\n",
    "def data(data_path):\n",
    "    print('Reading data')\n",
    "    X = np.load(data_path)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def pickle_object(obj):\n",
    "    import tempfile\n",
    "    import pickle\n",
    "    \n",
    "    fp = tempfile.mktemp()\n",
    "    with open(fp, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "    return fp\n",
    "\n",
    "@ex.main\n",
    "def train(pca):\n",
    "    X = data()\n",
    "    \n",
    "    print('Fitting PCA')\n",
    "    fit_pca = pca.fit(X)\n",
    "    \n",
    "    #option one, adding as sacred artifect\n",
    "    if save_model:\n",
    "            ex.add_artifact(pickle_object(fit_pca), 'fitted_{}.pkl'.format(pca.__class__.__name__))\n",
    "    \n",
    "    enc = fit_pca.transform(X)\n",
    "    \n",
    "    dec = fit_pca.inverse_transform(enc)\n",
    "    \n",
    "    mse = mean_squared_error(X, dec)\n",
    "    \n",
    "    #option two, writing to folder manually\n",
    "    scores = []\n",
    "    scores.append([pca.__class__.__name__, enc.shape, mse])\n",
    "    pd.DataFrame(scores).to_csv(os.path.join(ex.observers[0].dir, 'scores.csv'), header=False, index=False)\n",
    "    \n",
    "    return mse\n",
    "    \n",
    "\n",
    "ex.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run.json', 'fitted_KernelPCA.pkl', 'config.json', 'scores.csv', 'cout.txt']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"runs/Presentation ex 3/{}\".format(1)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Adding MongoDB observer\n",
    "Adding a MongoDB observer adds a whole lot of advantages to your experiment. If you have access to a mongodb server or you have your own server and want to go through the hassle of installing and setting up a safe mongoDB, that would be your best options. If both are not the case you can create a free acount at MongoDB Atlas for a 512mb MongoDB online server:\n",
    "\n",
    "https://www.mongodb.com/cloud/atlas/\n",
    "\n",
    "I will not go into detail about how to set this up, and from now I assume you have a secure server at hand. \n",
    "\n",
    "Advantages of using mongoDB:\n",
    "* Extra external place of secure sotrage\n",
    "* Query your results\n",
    "* Experiments receive a unique ID (especially usefull when developing on multiple devices)\n",
    "\n",
    "Building a debug mode is very much advised to not clog up your DB with failed experiments\n",
    "\n",
    "NOTE: pymongo will need to be installed to use this observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Presentation ex 4 - Running command 'train'\n",
      "INFO - Presentation ex 4 - Started run with ID \"15\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "Fitting PCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Presentation ex 4 - Result: 0.08322899043560028\n",
      "INFO - Presentation ex 4 - Completed after 0:00:04\n",
      "WARNING - Presentation ex 4 - An error ocurred in the '<sacred.observers.mongo.MongoObserver object at 0x7f978c364f28>' observer: Run contained an unserializable entry.(most likely in the info)\n",
      "WARNING - Presentation ex 4 - The observer '<sacred.observers.mongo.MongoObserver object at 0x7f978c364f28>' failed at some point during the run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7f978d09ecc0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# parameters\n",
    "DEBUG = False\n",
    "save_model = True\n",
    "\n",
    "from sacred import Experiment\n",
    "ex = Experiment('Presentation ex 4', interactive=True)\n",
    "\n",
    "from sacred.observers import FileStorageObserver\n",
    "ex.observers.append(FileStorageObserver.create(basedir=os.path.join('runs', ex.path)))\n",
    "if not DEBUG:\n",
    "    from sacred.observers import MongoObserver\n",
    "    ex.observers.append(MongoObserver.create(url='mongodb://user:pass@server1.mongodb.net:27017,server2.mongodb.net:27017,server3.mongodb.net:27017/test?ssl=true&replicaSet=Cluster0-shard-0&authSource=admin',\n",
    "                                            db_name='graduation'))\n",
    "\n",
    "@ex.config\n",
    "def config():\n",
    "    data_path = 'data/example_data.npy'\n",
    "    \n",
    "    pca = KernelPCA(fit_inverse_transform=True)\n",
    "\n",
    "@ex.capture\n",
    "def data(data_path):\n",
    "    print('Reading data')\n",
    "    X = np.load(data_path)\n",
    "    \n",
    "    return X\n",
    "\n",
    "@ex.main\n",
    "def train(pca):\n",
    "    X = data()\n",
    "    \n",
    "    print('Fitting PCA')\n",
    "    fit_pca = pca.fit(X)\n",
    "    \n",
    "    #option one, adding as sacred artifect\n",
    "    if save_model:\n",
    "            ex.add_artifact(pickle_object(fit_pca), 'fitted_{}.pkl'.format(name))\n",
    "    \n",
    "    enc = fit_pca.transform(X)\n",
    "    \n",
    "    dec = fit_pca.inverse_transform(enc)\n",
    "    \n",
    "    mse = mean_squared_error(X, dec)\n",
    "    \n",
    "    #option two, writing to folder manually\n",
    "    scores = []\n",
    "    scores.append([pca.__class__.__name__, enc.shape, mse])\n",
    "    pd.DataFrame(scores).to_csv(os.path.join(ex.observers[0].dir, 'scores.csv'), header=False, index=False)\n",
    "    \n",
    "    return mse\n",
    "    \n",
    "\n",
    "ex.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Aditional example for a Keras Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from tools.generator import DataGenerator\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from sacred import Experiment\n",
    "from sacred.observers import FileStorageObserver\n",
    "from sacred.observers import MongoObserver\n",
    "\n",
    "# DEBUG parameters\n",
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    save_model = True\n",
    "    tensorboard = True\n",
    "else:\n",
    "    save_model = False\n",
    "    tensorboard = False\n",
    "\n",
    "# create experiment:\n",
    "ex = Experiment('Autoencoder')\n",
    "\n",
    "# add file observer\n",
    "observer_path = '../runs/DEBUG' if DEBUG else '../runs'\n",
    "ex.observers.append(FileStorageObserver.create(basedir=os.path.join(observer_path, ex.path)))\n",
    "\n",
    "if not DEBUG:\n",
    "    # add mongo observer\n",
    "    with open('../tools/.mongo', 'r') as f:\n",
    "        auth_url = f.read()\n",
    "        ex.observers.append(MongoObserver.create(url=auth_url, db_name='graduation'))\n",
    "\n",
    "\n",
    "@ex.config\n",
    "def my_config():\n",
    "    data_path = r'../data/tcga-gbm_exp.npy'\n",
    "    cols, rows = np.load(data_path, mmap_mode='r').shape\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    encoding_dim = 100\n",
    "    samples_per_epoch = 1\n",
    "    nb_val_samples = 1\n",
    "    nb_epoch = 50\n",
    "\n",
    "\n",
    "@ex.capture\n",
    "def data(data_path, batch_size):\n",
    "    training_generator = DataGenerator(data_path, train=True, batch_size=batch_size).generate()\n",
    "    validation_generator = DataGenerator(data_path, train=False, batch_size=batch_size).generate()\n",
    "\n",
    "    return training_generator, validation_generator\n",
    "\n",
    "\n",
    "@ex.capture\n",
    "def model(encoding_dim, rows, batch_size):\n",
    "    input = Input(batch_shape=(batch_size, rows), name='input')\n",
    "    encoded = Dense(encoding_dim, activation='relu', name='encoded')(input)\n",
    "    decoded = Dense(rows, activation='sigmoid', name='decoded')(encoded)\n",
    "\n",
    "    autoencoder = Model(inputs=input, outputs=decoded)\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "@ex.automain\n",
    "def train(nb_epoch, samples_per_epoch, nb_val_samples):\n",
    "    training_generator, validation_generator = data()\n",
    "    out_path = ex.observers[0].dir\n",
    "\n",
    "    m = model()\n",
    "\n",
    "    m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    callbacks = []\n",
    "    if tensorboard:\n",
    "        callbacks.append(TensorBoard(log_dir=out_path, histogram_freq=1, write_graph=True, write_images=True))\n",
    "\n",
    "    m.summary()\n",
    "\n",
    "    history = m.fit_generator(generator=training_generator,\n",
    "                              steps_per_epoch=samples_per_epoch,\n",
    "                              epochs=nb_epoch,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=nb_val_samples,\n",
    "                              callbacks=callbacks)\n",
    "\n",
    "    if save_model:\n",
    "        m.save(os.path.join(out_path, 'model.h5'))\n",
    "\n",
    "    results = {}\n",
    "    for key in history.history.keys():\n",
    "        results[key] = history.history[key][-1]\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Find this notebook at:\n",
    "\n",
    "https://github.com/sakoarts/sacred_presentation\n",
    "\n",
    "sakoarts.nl/sacred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
